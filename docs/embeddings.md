# Embedding & Storage Strategy

## 1. Goals
- Keep Milli as the single canonical store for structured documents and chunk records.
- Support both keyword and vector similarity search with minimal duplication.
- Make embedder upgrades (model swaps, dimension changes) safe and reversible.

## 2. Record Shapes
- **Document record (one per decision)**
  - `id`: `{silo}::{doc_id}::doc`
  - `doc_type`: `"doc"`
  - `doc_id`: stable identifier derived from source metadata
  - `structured`: full `StructuredDecision` payload
  - `summary_short`: short abstract for lightweight recall
  - `ingest`: status (`pending` → `indexed`), timestamps, embedder key used, error state
- **Chunk record (N per decision)**
  - `id`: `{silo}::{doc_id}::chunk::{ord}`
  - `doc_type`: `"chunk"`
  - `doc_id`: parent document identifier
  - `ord`: 1-based position
  - `section`: optional semantic label (`header`, `sentencja`, …)
  - `content`: chunk body text
  - `decision.date`, `decision.result`, `parties.contracting_authority`, `parties.appellant`, `procurement.cpv_codes`, `issues.issue_key`, `identifiers.kio_docket`: copied into flat attributes for filtering
  - `_vectors.{embedder_key}`: embedding generated by the configured model (default `gemini-embedding-001`, dim 768)
- **Embedding job metadata (LMDB)**
  - `doc_id`, `silo`, `embedder_key`, `mode`
  - `chunk_count`, `content_hash`, timestamps, `stale`
  - `provider_kind`, `provider_job_id`, `submitted_batch_count`, `status`

All documents and chunks reside in the same Milli index per silo; vector payloads never leave Milli.

## 3. Embedder Policy
- Default embedder: `gemini-embedding-001`, 768 dimensions, stored under `_vectors.gemini-embedding-001`.
- Embed jobs submit inline batches to Gemini's Batch Embeddings API. `jobs embed` records the provider job id and falls back to synchronous embedding when the endpoint is unavailable.
- `jobs ingest` polls submitted jobs with exponential backoff, validates chunk hashes, and patches Milli once the provider reports success.
- Embedder upgrades create a new key (`_vectors.{new_key}`) alongside the old one. Queries switch keys once re-embedding completes; old keys can be deleted after validation.

## 4. Query Surfaces
- **Similarity search**: chunk records searched via `_vectors.{embedder_key}`; results re-hydrate document context by fetching the corresponding doc record.
- **Keyword/filter search**: `content` (chunks) and `summary_short` (docs) remain searchable; filters apply on flattened attributes listed above.

## 5. Ingest Flow (Batch or Near Real-Time)
1. OCR → structured extraction produces `StructuredDecision`.
2. Upsert the document + chunk records in Milli with `ingest.status = pending`; store `StructuredDecision` under the `structured` field.
3. Enqueue an embedding job in LMDB (doc_id, chunk_count, content_hash). No payload/result JSON is written to disk.
4. `jobs embed` submits the chunk bodies to Gemini's batch API. On success the job moves to `Embedding`; when the endpoint is disabled the command embeds synchronously and patches Milli immediately.
5. `jobs ingest` polls active jobs. Once the provider reports success it fetches vectors, validates counts + dimensions, and writes `_vectors.{embedder_key}` plus final ingest metadata. Failures mark the job `Failed` and retain the error snapshot.
6. Hash mismatches (doc re-indexed mid-flight) mark the job as `stale`/`Failed` so new jobs can be enqueued safely.

## 6. Cost Controls
- Only chunk bodies are embedded by default; document-level embeddings (e.g., `summary_short`) stay behind a feature flag to avoid unnecessary costs.
- Audit tooling (`zetesis-app audit structured`) samples PDFs, compares token coverage, and surfaces drift so prompt adjustments keep chunk completeness high.
